# SOMA Roadmap â€” Feb 21, 2026
*Honest assessment. Old docs were optimistic â€” this reflects actual current state.*

---

## âœ… What's Actually Working (As Of Today)

| System | Status | Notes |
|--------|--------|-------|
| Boot (Tier 1 + 2) | âœ… Stable | 255MB peak, no crashes |
| Chat responses | âœ… 3-5s | Was 34-35s timeouts â€” fixed |
| QuadBrain (LOGOS/AURORA/THALAMUS/PROMETHEUS) | âœ… | gemini-2.5-flash, no thinking budget waste |
| Gemini quota protection | âœ… | Background calls â†’ local SOMA-1T, user chat â†’ Gemini only |
| SOMArbiterV3 tree search | âœ… | Always local model now, never burns quota |
| GoalPlanner | âœ… | 20 active goals (was 956 zombie goals) |
| ExperienceReplayBuffer | âœ… | 149 experiences, 1.9MB (was 24GB) |
| FragmentRegistry | âœ… | 159 fragments, background calls use local model |
| Memory (MnemonicArbiter) | âœ… | SQLite warm/cold tiers active, Redis skipped (not installed) |
| EconomicCalendar | âœ… | 4,160 events loading correctly |
| NEMESIS Phase 1.3 | âœ… | API response validation in QuadBrain |

---

## ðŸ”´ Priority 1 â€” Foundation Gaps (Do These First)

### 1. SOMA-1T Fine-Tuning Pipeline
**Why:** Background reasoning currently uses raw 3.2B llama (weak). Training on SOMA's own conversations would make local reasoning actually useful.
**What's needed:**
- `TrainingDataExporter` is already running â€” verify it's actually saving conversations
- Run `train-soma-llama.py` on accumulated data
- Target: 500+ conversations â†’ fine-tune â†’ re-deploy as `soma-2t-v1`
**Effort:** 1-3 days (data collection) + GPU time

### 2. NEMESIS Phase 2 â€” Deployment & Goal Reality Checks
**Why:** Phase 1.3 validates API responses. Phase 2 extends this to autonomous decisions.
**What's needed:**
- Gate SelfModificationArbiter proposals through NEMESIS review
- Add NEMESIS check to GoalPlanner before creating new goals
- Add NEMESIS check to memory consolidation (don't consolidate hallucinated "facts")
**Effort:** 3-5 days

### 3. Verify Nighttime Learning Is Actually Working
**Why:** Docs say "autonomous learning at 4 AM" but we've never confirmed it runs and produces real results.
**What's needed:**
- Check hippocampus/ directory for consolidated memories from overnight runs
- Verify `NighttimeLearningOrchestrator` is completing full cycles
- Check if `TrainingDataExporter` graveyard has any data
**Effort:** 1 day audit

---

## ðŸŸ¡ Priority 2 â€” AGI Integration Wiring

*The AGI audit said 8.5/10 â€” most components exist but aren't connected.*

### 4. Theory of Mind Arbiter
- Doesn't exist yet. Needed for SOMA to model user intent, not just respond to words.
- Estimated: 1-2 weeks to build + integrate

### 5. Temporal Query System
- SOMA can't answer "what did we talk about last Tuesday?"
- `ConversationHistoryArbiter` exists but isn't wired for temporal queries
- Estimated: 1-2 days

### 6. CuriosityWebAccessConnector â€” Fix or Remove
- Currently gated behind `SOMA_LOAD_HEAVY` because it times out
- Either fix the timeout issue or remove it entirely and use EdgeWorkerOrchestrator instead
- Estimated: 1 day

---

## ðŸŸ¢ Priority 3 â€” Model Quality

### 7. Replace Gemini with Local SOMA Model (Long-term)
- Current dependency on Gemini API is a single point of failure
- Goal: SOMA-1T trained enough to handle user chat without Gemini
- Milestone: Local model handles 80% of queries, Gemini for complex/creative only
- Timeline: 2-3 months (needs training data accumulation)

### 8. PROMETHEUS (gemini-2.5-pro) â€” Validate It's Being Used
- PROMETHEUS is assigned to planning/strategy queries
- Verify it's actually being routed to (not LOGOS handling everything)
- If underused: intentionally trigger strategic queries to exercise it
- Estimated: 1 day audit

---

## ðŸ”µ Priority 4 â€” ASI Phase 2 (After Foundation Is Solid)

From `ASI_PLAN_2026-02-14.md` â€” only start these when Priority 1 is done:

- **Autonomous goal pursuit** â€” SOMA sets and pursues its own learning goals without prompting
- **Fragment crystallization** â€” High-value fragments auto-promote to core knowledge
- **Multi-modal grounding** â€” Vision + audio inputs wired into reasoning pipeline
- **Distributed intelligence** â€” Multiple SOMA nodes (GMN already has port 7777 ready)

---

## What Old Docs Got Wrong

| Old Claim | Reality |
|-----------|---------|
| "100/100 ASI-ready" (Dec 2025) | Multiple critical bugs existed (24GB memory, 956 zombie goals, 34s chat timeouts) |
| "Fully operational" | Was operational but severely degraded |
| "3-4 weeks to AGI" (AGI audit) | Premature â€” integration wiring is harder than estimated |
| NEMESIS Phase 1 "this week" | Phase 1.1-1.3 complete, but Phase 2 not started |
| Background learning "4 AM daily" | Scheduler runs but never confirmed producing real output |

---

## Immediate Next Steps (This Week)

1. **Audit TrainingDataExporter output** â€” is it saving real conversations?
2. **Check hippocampus/ overnight data** â€” verify nighttime learning ran
3. **NEMESIS Phase 2** â€” goal planner reality check integration
4. **Stability soak test** â€” run SOMA for 24h, check memory growth and experience accumulation

---
*Last updated: Feb 21, 2026*
*Previous roadmap docs: NEMESIS_ROADMAP.md, ASI_PLAN_2026-02-14.md, ROADMAP_TO_ASI.md (all partially outdated)*
